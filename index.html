<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Wei Lin</title>
  
  <meta name="author" content="Wei Lin">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Wei Lin <strong><FONT COLOR="#ff0000">(On Job Market)</FONT></strong></name>
              </p>
              
              <p>I am a research associate at the <a href="https://www.jku.at/en/institute-for-machine-learning/about-us/team/dr-wei-lin-msc/">Institute for Machine Learning</a> headed by Prof. <a href="https://scholar.google.at/citations?user=tvUH3WMAAAAJ&hl=en">Sepp Hochreiter</a> (Father of LSTM) at the Johannes Kepler University (JKU) Linz. 
              </p>
              
              <p> I did my PhD at the <a href="https://www.tugraz.at/institute/icg/home">Institute of Computer Graphics and Vision</a>, <a href="https://www.tugraz.at/home">Graz University of Technology</a> (TU Graz ICG) in Austria, supervised by Prof. <a href="https://scholar.google.com/citations?user=_pq05Q4AAAAJ&hl=en">Horst Bischof</a> (Professor and the Rector of TU Graz) and Prof. <a href="https://scholar.google.ca/citations?user=pxhCcH0AAAAJ&hl=en">Hilde Kuehne</a> (<a href="https://tuebingen.ai/">Tuebingen AI Center, University of Tuebingen</a>, <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a>)
              </p>
              <p>
              I also work in close collaboration with <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a> and <a href="https://www.rogerioferis.org/">Rogerio Feris</a> (Principal scientists and research manager) from the <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a>.
              </p>

              <p>
              	 Previously, I received my Master's degree in Electrical and Computer Engineering at the <a href="https://www.tum.de/">Technical University of Munich</a> in Germany.
              </p>
              <p>
              I like traveling &#129406; and learning languages &#127757; I speak English (C1), German (B2), Chinese (mother tongue) and some French.
              </p>
              <p style="text-align:center">
                <a href="mailto:wlin2021at@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data_lin/CV_Wei_Lin.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=JJRr8c8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/wlin-at">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/wei-lin-69a083169/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://twitter.com/WeiLinCV">Twitter</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images_lin/wei_lin.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images_lin/wei_lin.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <ul>
            <li><strong>02/2025</strong> Our paper <a href="https://arxiv.org/abs/2411.13317">IPLoc</a> is accepted at <strong>ICCV 2025!</strong> </li>
            <li><strong>02/2025</strong> Our paper <a href="https://gfmei.github.io/PerLA/">PerLA</a> is accepted at <strong>CVPR 2025!</strong> </li>
            <li><strong>02/2025</strong> I am happy to announce that I will co-organize <a href="https://sites.google.com/view/mmfm3rdworkshop/">the 3rd Workshop on "What is Next in Multimodal Foundation Models?"</a> as a program chair and challenge chair on <strong>CVPR 2025</strong> in Nashville! Follow us on <a href="https://x.com/MMFMWorkshop">X (Twitter)</a> and stay tuned! </li>
            <li><strong>01/2025</strong> Our paper <a href="https://arxiv.org/pdf/2410.10783">LiveXiv</a> is accepted at <strong>ICLR 2025!</strong> </li>
            <li><strong>11/2024</strong> Our paper <a href="https://arxiv.org/pdf/2408.03790">ViLGOD</a> won the <strong><FONT COLOR="#ff0000">Best Poster Award</FONT></strong> at <strong>BMVC 2024</strong>! </li>
            <li><strong>10/2024</strong> I gave a lightning talk about our work <a href="https://wlin-at.github.io/cad_vi">Comparison Visual Instruction Tuning</a> at the <a href="https://multimodalagents.github.io/">ECCV 2024 Workshop on Multimodal Agents!</a> </li>
            <li><strong>09/2024</strong> Our paper <a href="https://arxiv.org/abs/2406.08164">ConMe</a> is accepted at <strong>NeurIPS 2024 Datasets & Benchmarks Track!</strong> </li>
            <li><strong>08/2024</strong> Our paper <a href="https://arxiv.org/abs/2403.12736">Towards Multimodal In-Context Learning for Vision & Language Models</a> is accepted at <a href="https://multimodalagents.github.io/">ECCV 2024 Workshop on Multimodal Agents!</a> </li>
            <li><strong>07/2024</strong> Our paper <a href="https://arxiv.org/pdf/2408.03790">ViLGOD</a> is accepted as an <strong><FONT COLOR="#ff0000">Oral Presentation</FONT></strong> at <strong>BMVC 2024</strong>! </li>
            <li><strong>07/2024</strong> Our paper <a href="https://jmiemirza.github.io/Meta-Prompting/">Meta prompting</a> is accepted to <strong>ECCV 2024</strong>! </li>
            <li><strong>01/2024</strong> I am happy to announce that I will co-organize <a href="https://sites.google.com/view/2nd-mmfm-workshop/">the 2nd Workshop on "What is Next in Multimodal Foundation Models?"</a> as a program chair and challenge chair on <strong>CVPR 2024</strong> in Seattle! Follow us on <a href="https://twitter.com/MMFMWorkshop">X (Twitter)</a> and stay tuned! </li>
            <li><strong>10/2023</strong> I joined the <a href="https://www.jku.at/en/institute-for-machine-learning/about-us/team/wei-lin-msc/">Institute for Machine Learning</a> headed by Prof. <a href="https://scholar.google.at/citations?user=tvUH3WMAAAAJ&hl=en">Sepp Hochreiter</a> (Father of LSTM) at the Johannes Kepler University (JKU) Linz! </li>
            <li><strong>09/2023</strong> One paper is accepted to <strong>NeurIPS 2023</strong>! </li>
            <li><strong>09/2023</strong> Our ICCV paper <a href="https://wlin-at.github.io/maxi">MAtch, eXpand and Improve (MAXI)</a> is accepted as an <strong><FONT COLOR="#ff0000">Oral Presentation</FONT></strong> at the <strong>ICCV 2023 Workshop</strong> <a href="https://sites.google.com/view/perdream/home">PerDream: PERception, Decision making and REAsoning through Multimodal foundational modeling</a>! </li>
            <li><strong>07/2023</strong> Two papers are accepted to <strong>ICCV 2023</strong>! </li>
            <li><strong>07/2023</strong> I attended the <a href="https://iplab.dmi.unict.it/icvss2023/Home">International Computer Vision Summer School 2023</a>! </li>
            <li><strong>04/2023</strong> Application to the <a href="https://iplab.dmi.unict.it/icvss2023/Home">International Computer Vision Summer School 2023</a> is accepted (acceptance rate 27%)! </li>
            <li><strong>03/2023</strong> Application to the <a href="https://cvpr2023.thecvf.com/Conferences/2023/CallForDoctoralConsortium">CVPR 2023 Doctoral Consortium</a> is accepted (acceptance rate 13%)! </li>
            <li><strong>03/2023</strong> One paper is accepted to <strong>Robotics and Automation Letters 2023</strong>! </li>
            <li><strong>02/2023</strong> Two papers are accepted to <strong>CVPR 2023</strong>! </li>
            <li><strong>07/2022</strong> One paper is accepted to <strong>ECCV 2022</strong>! </li>
            </ul>
              <heading>Research</heading>
              <p>
                I am interested in computer vision and machine learning in general. My research is mainly about multimodal large language models, video understanding, reinforcement learning and world models.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
       
        <tr onmouseout="pLSTM_stop()" onmouseover="pLSTM_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='LiveXiv_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/pLSTM_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function maxi_start() {
                  document.getElementById('IPLoc_image').style.opacity = "1";
                }

                function maxi_stop() {
                  document.getElementById('IPLoc_image').style.opacity = "0";
                }
                maxi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            
      			<papertitle>pLSTM: parallelizable Linear Source Transition Mark networks</papertitle>
    		 </a>
              <br>
              <a href="https://korbi.ai/">Korbinian P√∂ppel</a>,
              <a href="https://www.jku.at/en/institute-for-machine-learning/about-us/team/richard-freinschlag-msc/">Richard Freinschlag</a>, 
              <a href="https://scholar.google.com/citations?user=rEfdigIAAAAJ&hl=de">Thomas Schmied</a>, <br>
              <strong>Wei Lin</strong>, 
              <a href="https://scholar.google.at/citations?user=tvUH3WMAAAAJ&hl=en">Sepp Hochreiter</a>,
              <br>
        	<em>Arxiv</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2506.11997">arxiv</a>
        /
              code
        /
              video
              <p></p>
            </td>
          </tr>

        <tr onmouseout="pLSTM_stop()" onmouseover="pLSTM_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='LiveXiv_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/STSbench_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function maxi_start() {
                  document.getElementById('IPLoc_image').style.opacity = "1";
                }

                function maxi_stop() {
                  document.getElementById('IPLoc_image').style.opacity = "0";
                }
                maxi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            
      			<papertitle>STSBench: A Spatio-temporal Scenario Benchmark for Multi-modal Large Language Models in Autonomous Driving</papertitle>
    		 </a>
              <br>
              <a href="https://scholar.google.com/citations?user=Mg5Vlp8AAAAJ&hl=en">Christian Fruhwirth-Reisinger</a>,
              <a href="https://graz.elsevierpure.com/en/persons/du%C5%A1an-mali%C4%87">Dusan Malic</a>, 
              <strong>Wei Lin</strong>, <br>
              <a href="https://dschinagl.github.io/">David Schinagl</a>, 
              <a href="https://samschulter.github.io/">Samuel Schulter</a>,
              <a href="https://snototter.github.io/research/">Horst Possegger</a>
              <br>
        	<em>Arxiv</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2506.06218">arxiv</a>
        /
              code
        /
              video
              <p></p>
            </td>
          </tr>
       



       
        <tr onmouseout="IPLoc_stop()" onmouseover="IPLoc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='LiveXiv_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/IPLoc_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function maxi_start() {
                  document.getElementById('IPLoc_image').style.opacity = "1";
                }

                function maxi_stop() {
                  document.getElementById('IPLoc_image').style.opacity = "0";
                }
                maxi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            
      			<papertitle>Teaching VLMs to Localize Specific Objects from In-context Examples</papertitle>
    		 </a>
              <br>
              <a href="https://scholar.google.co.il/citations?user=ER4dt8cAAAAJ&hl=iw">Sivan Doveh</a>,
              <a href="https://scholar.google.com/citations?user=z4Jk_I4AAAAJ&hl=en">Nimrod Shabtay</a>, 
              <strong>Wei Lin</strong>, <br>
              <a href="https://scholar.google.co.il/citations?user=7ttMZRUAAAAJ&hl=en">Eli Schwartz</a>, 
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://english.tau.ac.il/profile/raja">Raja Giryes</a>,  <br>
              <a href="https://www.rogerioferis.org/">Rogerio Feris</a>, 
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a>,
              <a href="https://scholar.google.com/citations?user=pfGI-KcAAAAJ&hl=en">James Glass</a>,  <br>
              <a href="https://scholar.google.co.uk/citations?user=uU_V_PsAAAAJ&hl=en">Assaf Arbelle</a>, 
              <a href="https://scholar.google.com/citations?user=XOfA8ckAAAAJ&hl=en">Shimon Ullman</a>,
              <a href="https://jmiemirza.github.io/">Muhammad Jehanzeb Mirza</a>  
              <br>
        	<em>ICCV</em>, 2025
              <br>
              <a href="https://arxiv.org/pdf/2411.13317?">arxiv</a>
        /
              <a href="https://github.com/SivanDoveh/IPLoc">code</a>
        /
              video
              <p></p>
            </td>
          </tr>
       
       
               <tr onmouseout="PerLA_stop()" onmouseover="PerLA_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='PerLA_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/PerLA_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function maxi_start() {
                  document.getElementById('PerLA_image').style.opacity = "1";
                }

                function maxi_stop() {
                  document.getElementById('PerLA_image').style.opacity = "0";
                }
                maxi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            
             <a href="https://gfmei.github.io/PerLA/">
      			<papertitle>PerLA: Perceptive 3D Language Assistant</papertitle>
    		 </a>
              <br>
              <a href="https://scholar.google.com/citations?user=VsmIGqsAAAAJ&hl=zh-CN">Guofeng Mei</a>,
              <strong>Wei Lin</strong>, 
              <a href="https://scholar.google.com/citations?user=djO2pVUAAAAJ&hl=it">Luigi Riz</a>,  <br>
              <a href="https://scholar.google.com/citations?user=4t9fSdwAAAAJ&hl=en">Yujiao Wu</a>, 
              <a href="https://fabiopoiesi.github.io/">Fabio Poiesi</a>,
              <a href="https://www.yimingwang.it/">Yiming Wang</a>
              <br>
        	<em>CVPR</em>, 2025
              <br>
              <a href="https://arxiv.org/pdf/2411.19774?">arxiv</a>
        /
              <a href="https://github.com/gfmei/PerLA">code</a>
        /
              video
              <p></p>
            </td>
          </tr>
       
      
       
       
       
          <tr onmouseout="LiveXiv_stop()" onmouseover="LiveXiv_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='LiveXiv_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/LiveXiv_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function maxi_start() {
                  document.getElementById('LiveXiv_image').style.opacity = "1";
                }

                function maxi_stop() {
                  document.getElementById('LiveXiv_image').style.opacity = "0";
                }
                maxi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            
      			<papertitle>LiveXiv--A Multi-Modal Live Benchmark Based on Arxiv Papers Content</papertitle>
    		 </a>
              <br>
              <a href="https://scholar.google.com/citations?user=z4Jk_I4AAAAJ&hl=en">Nimrod Shabtay</a>, 
              <a href="https://scholar.google.com/citations?user=CJbgmnkAAAAJ&hl=en">Felipe Maia Polo</a>, 
              <a href="https://scholar.google.co.il/citations?user=ER4dt8cAAAAJ&hl=iw">Sivan Doveh</a>, <br>
              <strong>Wei Lin</strong>,
              <a href="https://jmiemirza.github.io/">Muhammad Jehanzeb Mirza</a>,
              <a href="https://scholar.google.com/citations?user=8b8IhUYAAAAJ&hl=en">Leshem Choshen</a>,  <br>
              <a href="https://scholar.google.com/citations?user=QjBF9sUAAAAJ&hl=en">Mikhail Yurochkin</a>, 
              <a href="https://yuekai.github.io/">Yuekai Sun</a>,
              <a href="https://scholar.google.co.uk/citations?user=uU_V_PsAAAAJ&hl=en">Assaf Arbelle</a>, <br>
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a>,
              <a href="https://english.tau.ac.il/profile/raja">Raja Giryes</a>
              <br>
        	<em>ICLR</em>, 2025
              <br>
              <a href="https://arxiv.org/pdf/2410.10783">arxiv</a>
        /
              <a href="https://huggingface.co/datasets/LiveXiv/LiveXiv"> &#129303 Dataset</a>
        /
              <a href="https://github.com/NimrodShabtay/LiveXiv">code</a>
        /
              video
              <p></p>
            </td>
          </tr>
       
       
       
                <tr onmouseout="glov_stop()" onmouseover="glov_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='glov_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/GLOV_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function maxi_start() {
                  document.getElementById('cadvi_image').style.opacity = "1";
                }

                function maxi_stop() {
                  document.getElementById('cadvi_image').style.opacity = "0";
                }
                maxi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            
            <a href="https://jmiemirza.github.io/GLOV/">
      			<papertitle>GLOV: Guided Large Language Models as Implicit Optimizers for Vision Language Models</papertitle>
    		 </a>
              <br>
              <a href="https://jmiemirza.github.io/">Muhammad Jehanzeb Mirza</a>,
              <a href="https://scholar.google.com/citations?user=G6ema1YAAAAJ&hl=en">Mengjie Zhao</a>, 
              <a href="https://scholar.google.co.jp/citations?user=gIzJ2sQAAAAJ&hl=ja">Zhuoyuan Mao</a>, <br>
              <a href="https://scholar.google.co.il/citations?user=ER4dt8cAAAAJ&hl=iw">Sivan Doveh</a>,
              <strong>Wei Lin</strong>,
              <a href="https://scholar.google.com/citations?user=cshJtrQAAAAJ&hl=en">Paul Gavrikov</a>,  <br>
              <a href="https://mdorkenwald.com/">Michael Dorkenwald</a>, 
              <a href="https://scholar.google.com/citations?user=p27Iqt4AAAAJ&hl=zh-CN">Shiqi Yang</a>,
              <a href="http://sauravjha.com.np/">Saurav Jha</a>,  <br>
              <a href="https://scholar.google.co.jp/citations?user=lv41luwAAAAJ&hl=ja">Hiromi Wakaki</a>, 
              <a href="https://www.yukimitsufuji.com/">Yuki Mitsufuji</a>, 
              <a href="https://snototter.github.io/research/">Horst Possegger</a>  <br>
              <a href="https://www.rogerioferis.org/">Rogerio Feris</a>, 
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a>,
              <a href="https://scholar.google.com/citations?user=pfGI-KcAAAAJ&hl=en">James Glass</a>
              <br>
        	<em>Arxiv</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2410.06154">arxiv</a>
        /
              <a href="https://github.com/jmiemirza/GLOV">code</a>
        /
              video
              <p></p>
            </td>
          </tr>
       
         <tr onmouseout="cadvi_stop()" onmouseover="cadvi_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cadvi_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/cad_vi_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function maxi_start() {
                  document.getElementById('cadvi_image').style.opacity = "1";
                }

                function maxi_stop() {
                  document.getElementById('cadvi_image').style.opacity = "0";
                }
                maxi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
		<a href="https://wlin-at.github.io/cad_vi">
      			<papertitle>Comparison Visual Instruction Tuning</papertitle>
    		 </a>
              <br>
              <strong>Wei Lin</strong>,
              <a href="https://jmiemirza.github.io/">Muhammad Jehanzeb Mirza</a>,
              <a href="https://scholar.google.co.il/citations?user=ER4dt8cAAAAJ&hl=iw">Sivan Doveh</a>, <br>
              <a href="https://www.rogerioferis.org/">Rogerio Feris</a>, 
              <a href="https://english.tau.ac.il/profile/raja">Raja Giryes</a>, 
              <a href="https://scholar.google.at/citations?user=tvUH3WMAAAAJ&hl=en">Sepp Hochreiter</a>, <br>
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a>
              <br>
        	In collaboration with the <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a>
              <br>
        	<em>Arxiv</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2406.09240">arxiv</a>
        /
              <a href="https://huggingface.co/datasets/wlin21at/CaD-Inst"> &#129303 Dataset</a>
        /
              <a href="https://github.com/wlin-at/CaD-VI">code</a>
        /
              video
              <p></p>
              <p>an approach for collection of visual instructions that improves Commonality and difference spoting capabilities for Large Multimodal Modes</p>
            </td>
          </tr>
       
       
       
           <tr onmouseout="conme_stop()" onmouseover="conme_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='conme_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/conme_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function maxi_start() {
                  document.getElementById('conme_image').style.opacity = "1";
                }

                function maxi_stop() {
                  document.getElementById('conme_image').style.opacity = "0";
                }
                maxi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
		
      	<papertitle>Conme: Rethinking Evaluation of Compositional Reasoning for Modern VLMs</papertitle>
    		 
              <br>
              *<a href="https://www.linkedin.com/in/ireneyhuang/">Irene Huang</a>,
              *<strong>Wei Lin</strong>,
              *<a href="https://jmiemirza.github.io/">Muhammad Jehanzeb Mirza</a>,
              Jacob Hansen,
              <a href="https://scholar.google.co.il/citations?user=ER4dt8cAAAAJ&hl=iw">Sivan Doveh</a>, <br>
              <a href="https://victorbutoi.github.io/">Victor Ion Butoi</a>,
              <a href="https://roeiherz.github.io/">Roei Herzig</a>,
              <a href="https://scholar.google.co.uk/citations?user=uU_V_PsAAAAJ&hl=en">Assaf Arbelle</a>,
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://scholar.google.com/citations?user=bh-uRFMAAAAJ&hl=en">Trevor Darrell</a>,
              <a href="https://people.csail.mit.edu/ganchuang/">Chuang Gan</a>, 
              <a href="https://scholar.google.com/citations?user=FNhl50sAAAAJ&hl=en">Aude Oliva</a>, 
              <a href="https://www.rogerioferis.org/">Rogerio Feris</a>, 
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a>
              (*equal contribution)
              <br>
        	In collaboration with the <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a>
              <br>
        	<em>NeurIPS</em>, 2024 Datasets & Benchmarks Track
              <br>
              <a href="https://arxiv.org/abs/2406.08164">arxiv</a>
        /
              <a href="https://huggingface.co/conme/ConMe"> &#129303 Dataset</a>
        /
              <a href="https://github.com/jmiemirza/ConMe">code</a>
        /
              video
              <p></p>

            </td>
          </tr>
       
		
         <tr onmouseout="mpvr_stop()" onmouseover="mpvr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mpvr_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/mpvr_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function maxi_start() {
                  document.getElementById('mpvr_image').style.opacity = "1";
                }

                function maxi_stop() {
                  document.getElementById('mpvr_image').style.opacity = "0";
                }
                maxi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
		<a href="https://jmiemirza.github.io/Meta-Prompting/">
      			<papertitle>Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs</papertitle>
    		 </a>
              <br>
              <a href="https://jmiemirza.github.io/">Muhammad Jehanzeb Mirza</a>,
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a>,
              <strong>Wei Lin</strong>,
              <a href="https://scholar.google.co.il/citations?user=ER4dt8cAAAAJ&hl=iw">Sivan Doveh</a>, <br>
              <a href="https://scholar.google.com/citations?user=hFcNhWEAAAAJ&hl=en">Jakub Micorek</a>, 
              <a href="https://scholar.google.com/citations?user=oDDqnQ4AAAAJ&hl=en">Mateusz Kozinski</a>, 
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://snototter.github.io/research/">Horst Possegger</a>
              
              <br>
        	In collaboration with the <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a>
              <br>
        	<em>ECCV</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2403.11755">arxiv</a>
        /
              <a href="https://github.com/jmiemirza/Meta-Prompting">code</a>
        /
              video
              <p></p>

            </td>
          </tr>
          
           <tr onmouseout="vilgod_stop()" onmouseover="lizo_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='vilgod_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/ViLGOD_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function lizo_start() {
                  document.getElementById('vilgod_image').style.opacity = "1";
                }

                function lizo_stop() {
                  document.getElementById('vilgod_image').style.opacity = "0";
                }
                lizo_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
      		   <papertitle>Vision-Language Guidance for LiDAR-based Unsupervised 3D Object Detection</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=Mg5Vlp8AAAAJ&hl=en">Christian Fruhwirth-Reisinger</a>,
              <strong>Wei Lin</strong>, 
              <a href="https://graz.elsevierpure.com/en/persons/du%C5%A1an-mali%C4%87">Dusan Malic</a>, <br>
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>,
              <a href="https://snototter.github.io/research/">Horst Possegger</a>
              


              <br>
        BMVC, 2024 <strong><FONT COLOR="#ff0000">Oral Presentation & Best Poster Award</FONT></strong>
              <br>
             <a href="https://arxiv.org/pdf/2408.03790">arxiv</a>
        /
              <a href="https://github.com/chreisinger/ViLGOD">code</a>
        /
              video
              <p></p>

            </td>
          </tr> 
          
          
           <tr onmouseout="multimodal_icl_stop()" onmouseover="multimodal_icl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='multimodal_icl_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/multimodal_ICL_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function lizo_start() {
                  document.getElementById('multimodal_icl_image').style.opacity = "1";
                }

                function lizo_stop() {
                  document.getElementById('multimodal_icl_image').style.opacity = "0";
                }
                lizo_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
      		   <papertitle>Towards Multimodal In-Context Learning for Vision & Language Models</papertitle>
              <br>
              <a href="https://scholar.google.co.il/citations?user=ER4dt8cAAAAJ&hl=iw">Sivan Doveh</a>,
              <a href="https://scholar.google.cz/citations?user=yF-VcRMAAAAJ&hl=cs">Shaked Perek</a>,
              <a href="https://scholar.google.com/citations?user=cES2rkAAAAAJ&hl=en">Muhammad Jehanzeb Mirza</a>, <br>
              <strong>Wei Lin</strong>, 
              <a href="https://scholar.google.co.il/citations?user=hVyhT-gAAAAJ&hl=en">Amit Alfassy</a>,
              <a href="https://scholar.google.co.uk/citations?user=uU_V_PsAAAAJ&hl=en">Assaf Arbelle</a>, <br>
              <a href="https://scholar.google.com/citations?user=XOfA8ckAAAAJ&hl=en">Shimon Ullman</a>,
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a>
              


              <br>
        ECCV 2024 Workshop on Multimodal Agents
              <br>
             <a href="https://arxiv.org/abs/2403.12736">arxiv</a>
        /
             code
        /
              video
              <p></p>

            </td>
          </tr> 
          
          
           <tr onmouseout="lizo_stop()" onmouseover="lizo_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lizo_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/shapetastic_ood_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function lizo_start() {
                  document.getElementById('lizo_image').style.opacity = "1";
                }

                function lizo_stop() {
                  document.getElementById('lizo_image').style.opacity = "0";
                }
                lizo_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
      		   <papertitle>Overlooked Aspects in the Evaluation of Out-Of-Distribution Detection Methods</papertitle>
              <br>
              <a href="https://scholar.google.at/citations?user=7nA0xUIAAAAJ&hl=de">*Bernhard Lehner</a>,
               *Christian Huber,
               <a href="https://scholar.google.at/citations?user=_DuPpPEAAAAJ&hl=en">Bernhard Moser</a>, <br>
              <a href="https://www.claus-hofmann.com/">Claus Hofmann</a>, 
              <strong>Wei Lin</strong>, 
              <a href="https://scholar.google.at/citations?user=tvUH3WMAAAAJ&hl=en">Sepp Hochreiter</a> (*equal contribution)


              <br>
        Arxiv, 2024
              <br>
              arxiv
        /
              code
        /
              video
              <p></p>

            </td>
          </tr> 

	

         <tr onmouseout="lafter_stop()" onmouseover="lafter_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lafter_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/lafter_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function lafter_start() {
                  document.getElementById('lafter_image').style.opacity = "1";
                }

                function lafter_stop() {
                  document.getElementById('lafter_image').style.opacity = "0";
                }
                lafter_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
      		   <papertitle>LaFTer: Label-Free Tuning of Zero-shot Classifier using Language and Unlabeled Image Collections</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=cES2rkAAAAAJ&hl=en">Muhammad Jehanzeb Mirza</a>,
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a>,
              <strong>Wei Lin</strong>, <br>
              <a href="https://scholar.google.com/citations?user=oDDqnQ4AAAAJ&hl=en">Mateusz Kozinski</a>, 
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://www.rogerioferis.org/">Rogerio Feris</a>, 
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>


              <br>
        NeurIPS, 2023
              <br>
              <a href="https://arxiv.org/abs/2305.18287">arxiv</a>
        /
              code
        /
              video
              <p></p>

            </td>
          </tr> 

         <tr onmouseout="maxi_stop()" onmouseover="maxi_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='maxi_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/maxi_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function maxi_start() {
                  document.getElementById('maxi_image').style.opacity = "1";
                }

                function maxi_stop() {
                  document.getElementById('maxi_image').style.opacity = "0";
                }
                maxi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
		<a href="https://wlin-at.github.io/maxi">
      			<papertitle>MAtch, eXpand and Improve: Unsupervised Finetuning for Zero-Shot Action Recognition with Language Knowledge</papertitle>
    		 </a>
              <br>
              <strong>Wei Lin</strong>,
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a>,
              <a href="https://scholar.google.com/citations?user=qZtU1L4AAAAJ&hl=en">Nina Shvetsova</a>, <br>
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://scholar.google.com/citations?user=oDDqnQ4AAAAJ&hl=en">Mateusz Kozinski</a>, 
              <a href="https://rpand002.github.io/">Rameswar Panda</a>, <br>
              <a href="https://www.rogerioferis.org/">Rogerio Feris</a>, 
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              <br>
        	In collaboration with the <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a>
              <br>
        	<em>ICCV</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2303.08914">arxiv</a>
        /
              <a href="https://github.com/wlin-at/MAXI">code</a>
        /
              <a href="https://youtu.be/gwaUBpJ-RcI">video</a>
              <p></p>
              <p>Unsupervised finetuning of Vision-Language models for zero-shot and few-shot action recognition, with GPT3 text expansion and video frame captioning.</p>
            </td>
          </tr>
          
         <tr onmouseout="tap_stop()" onmouseover="tap_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='tap_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/tap_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function tap_start() {
                  document.getElementById('tap_image').style.opacity = "1";
                }

                function tap_stop() {
                  document.getElementById('tap_image').style.opacity = "0";
                }
                tap_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
      		   <papertitle>TAP: Targeted Prompting for Task Adaptive Generation of Textual Training Instances for Visual Classification</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=cES2rkAAAAAJ&hl=en">Muhammad Jehanzeb Mirza</a>,
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a>,
              <strong>Wei Lin</strong>, <br>
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://www.rogerioferis.org/">Rogerio Feris</a>, 
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>


              <br>
        Arxiv, 2023
              <br>
              <a href="https://arxiv.org/abs/2309.06809">arxiv</a>
        /
              <a href="https://github.com/jmiemirza/TAP">code</a>
        /
              video
              <p></p>

            </td>
          </tr> 
          
          

          
          
          <tr onmouseout="mate_stop()" onmouseover="mate_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mate_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/mate_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function mate_start() {
                  document.getElementById('mate_image').style.opacity = "1";
                }

                function mate_stop() {
                  document.getElementById('mate_image').style.opacity = "0";
                }
                mate_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>MATE: Masked Autoencoders are Online 3D Test-Time Learners</papertitle>
              <br>
              *<a href="https://scholar.google.com/citations?user=cES2rkAAAAAJ&hl=en">Muhammad Jehanzeb Mirza</a>,
              *<a href="https://dlsrbgg33.github.io/">Inkyu Shin</a>,
              *<strong>Wei Lin</strong>, 
              <br>
              Andreas Schriebl,
              <a href="https://www.researchgate.net/profile/Kunyang-Sun">Kunyang Sun</a>,
              <a href="https://sites.google.com/view/jaesungchoe">Jaesung Choe</a>,
              <br>
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://scholar.google.com/citations?user=oDDqnQ4AAAAJ&hl=en">Mateusz Kozinski</a>, 
              <a href="https://scholar.google.com/citations?user=XA8EOlEAAAAJ&hl=en">In So Kweon</a>,
              <br>
              <a href="https://sites.google.com/site/kjyoon/">Kun-Jin Yoon</a>, 
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              (*equal contribution)
              <br>
        	<em>ICCV</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2211.11432">arxiv</a>
        /
              <a href="https://github.com/jmiemirza/MATE">code</a>
        /
              video
              <p></p>

            </td>
          </tr>  		
			
     
            <tr onmouseout="vitta_stop()" onmouseover="vitta_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='vitta_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/vitta_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function vitta_start() {
                  document.getElementById('vitta_image').style.opacity = "1";
                }

                function vitta_stop() {
                  document.getElementById('vitta_image').style.opacity = "0";
                }
                vitta_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://wlin-at.github.io/vitta">
              <papertitle>Video Test-Time Adaptation for Action Recognition</papertitle>
              </a>
              <br>
              <strong>*Wei Lin</strong>,
              *<a href="https://scholar.google.com/citations?user=cES2rkAAAAAJ&hl=en">Muhammad Jehanzeb Mirza</a>,
              <a href="https://scholar.google.com/citations?user=oDDqnQ4AAAAJ&hl=en">Mateusz Kozinski</a>, <br>
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              (*equal contribution)
              <br>
        <em>CVPR</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2211.15393">arxiv</a>
        /
        <a href="https://huggingface.co/datasets/wlin21at/ViTTA"> &#129303 Dataset</a>
        /
              <a href="https://github.com/wlin-at/ViTTA">code</a>
        /
              <a href="https://www.youtube.com/watch?v=RzdYgE1hN2o">video</a>
              <p></p>
              <p>Test-time adaptation of video action recognition against common distribution shifts.</p>
            </td>
          </tr> 
          
       
          <tr onmouseout="actmad_stop()" onmouseover="actmad_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='actmad_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/actmad_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function actmad_start() {
                  document.getElementById('actmad_image').style.opacity = "1";
                }

                function actmad_stop() {
                  document.getElementById('actmad_image').style.opacity = "0";
                }
                actmad_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://jmiemirza.github.io/ActMAD/">
      			<papertitle>ActMAD: Activation Matching to Align Distributions for Test-Time-Training</papertitle>
    		 </a>
              <br>
              <a href="https://scholar.google.com/citations?user=cES2rkAAAAAJ&hl=en">Muhammad Jehanzeb Mirza</a>,
              <a href="https://www.irs.kit.edu/People_1853.php">Pol JaneÃÅ Soneira</a>,
              <strong>Wei Lin</strong>, <br>
              <a href="https://scholar.google.com/citations?user=oDDqnQ4AAAAJ&hl=en">Mateusz Kozinski</a>, 
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>


              <br>
        <em>CVPR</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2211.12870">arxiv</a>
        /
              <a href="https://github.com/jmiemirza/ActMAD">code</a>
        /
              video
              <p></p>

            </td>
          </tr> 
          
      

          
          
       <tr onmouseout="lizo_stop()" onmouseover="lizo_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lizo_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/lizo_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function lizo_start() {
                  document.getElementById('lizo_image').style.opacity = "1";
                }

                function lizo_stop() {
                  document.getElementById('lizo_image').style.opacity = "0";
                }
                lizo_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
      		   <papertitle>Unsupervised Class-aware 3D Object Detection in LiDAR Point Clouds</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=Mg5Vlp8AAAAJ&hl=en">Christian Fruhwirth-Reisinger</a>,
              <strong>Wei Lin</strong>, 
              <a href="https://graz.elsevierpure.com/en/persons/du%C5%A1an-mali%C4%87">Dusan Malic</a>, <br>
              <a href="https://dschinagl.github.io/">David Schinagl</a>, 
              <a href="https://scholar.google.at/citations?user=Vt2vlgIAAAAJ&hl=de">Georg Krispel</a>, 
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>


              <br>
        Arxiv, 2023
              <br>
              arxiv
        /
              code
        /
              video
              <p></p>

            </td>
          </tr> 
          
          

     
     
       <tr onmouseout="cycda_stop()" onmouseover="cycda_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cycda_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images_lin/cycda_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/cycda_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function cycda_start() {
                  document.getElementById('cycda_image').style.opacity = "1";
                }

                function cycda_stop() {
                  document.getElementById('cycda_image').style.opacity = "0";
                }
                cycda_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>CycDA: Unsupervised Cycle Domain Adaptation to Learn from Image to Video</papertitle>
              <br>
              <strong>Wei Lin</strong>,
              <a href="https://annusha.github.io/">Anna Kukleva</a>,
              <a href="https://www.researchgate.net/profile/Kunyang-Sun">Kunyang Sun</a>, <br>
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              <br>
        <em>ECCV</em>, 2022
              <br>
              <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136630684.pdf">paper</a>
        /
              <a href="https://arxiv.org/abs/2203.16244">arxiv</a>
        /
              <a href="https://github.com/wlin-at/CycDA">code</a>
        /
              <a href="https://www.youtube.com/watch?v=0mUuhkL_3zM">video</a>
              <p></p>
              <p>Unsupervised image-to-video domain adaptation.</p>
            </td>
          </tr> 
          
 
          
         <tr onmouseout="cycdaex_stop()" onmouseover="cycdaex_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cycdaex_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/cycda_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function cycdaex_start() {
                  document.getElementById('cycdaex_image').style.opacity = "1";
                }

                function cycdaex_stop() {
                  document.getElementById('cycdaex_image').style.opacity = "0";
                }
                cycdaex_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Extended Abstract CycDA: Unsupervised Cycle Domain Adaptation to Learn from Image to Video</papertitle>
              <br>
              <strong>Wei Lin</strong>,
              <a href="https://annusha.github.io/">Anna Kukleva</a>,
              <a href="https://www.researchgate.net/profile/Kunyang-Sun">Kunyang Sun</a>, <br>
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              <br>
        <em>ECCV Workshop of Out Of Distribution Generalization in Computer Vision</em>, 2022
              <br>
              <a href="http://www.ood-cv.org/camera-ready/2/CycDA_Out_of_distribution_generalization_workshop_lin.pdf">paper</a>
        /
              <a href="https://github.com/wlin-at/CycDA">code</a>
        /
              <a href="https://www.youtube.com/watch?v=0mUuhkL_3zM">video</a>
              <p></p>
            </td>
          </tr> 
          
         <tr onmouseout="airda_stop()" onmouseover="airda_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='airda_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images_lin/airda_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/airda_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function airda_start() {
                  document.getElementById('airda_image').style.opacity = "1";
                }

                function airda_stop() {
                  document.getElementById('airda_image').style.opacity = "0";
                }
                airda_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>AIR-DA: Adversarial Image Reconstruction for Unsupervised Domain Adaptive Object Detection</papertitle>
              <br>
              <a href="https://www.researchgate.net/profile/Kunyang-Sun">Kunyang Sun</a>,
              <strong>Wei Lin</strong>,
              Haoqin Shi, <br>
              <a href="https://scholar.google.com/citations?user=GePqbSgAAAAJ&hl=en">Zhengming Zhang</a>, 
              <a href="https://scholar.google.com/citations?user=qd9zdUMAAAAJ&hl=zh-CN">Yongming Huang</a>,
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              <br>
        	IEEE Robotics and Automation Letters (RA-L) 2023
              <br>
                                    <a href="https://ieeexplore.ieee.org/document/10103159">paper</a>
        /
              <a href="https://arxiv.org/abs/2303.15377">arxiv</a>
        /
              code
        /
              video
              <p></p>
            </td>
          </tr> 
          
          
         <tr onmouseout="taec_stop()" onmouseover="taec_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='taec_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images_lin/taec_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/taec_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function taec_start() {
                  document.getElementById('taec_image').style.opacity = "1";
                }

                function taec_stop() {
                  document.getElementById('taec_image').style.opacity = "0";
                }
                taec_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>TAEC: Unsupervised Action Segmentation with Temporal-Aware Embedding and Clustering</papertitle>
              <br>
              <strong>Wei Lin</strong>,
              <a href="https://annusha.github.io/">Anna Kukleva</a>,
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, <br>
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              <br>
        <em>Computer Vision Winter Workshop</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2303.05166">arxiv</a>
        /
              code
        /
              video
              <p></p>
            </td>
          </tr> 
          
       
       
          <tr onmouseout="dilam_stop()" onmouseover="dilam_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dilam_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/dilam_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function dilam_start() {
                  document.getElementById('dilam_image').style.opacity = "1";
                }

                function dilam_stop() {
                  document.getElementById('dilam_image').style.opacity = "0";
                }
                dilam_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
      		   <papertitle>Sit Back and Relax: Learning to Drive Incrementally in All Weather Conditions</papertitle>
              <br>
              <a href="https://online.tugraz.at/tug_online/visitenkarte.show_vcard?pPersonenGruppe=3&pPersonenId=9D78E35CF4C05168">Stefan Leitner</a>,
              <a href="https://scholar.google.com/citations?user=cES2rkAAAAAJ&hl=en">Muhammad Jehanzeb Mirza</a>,
              <strong>Wei Lin</strong>, <br>
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/people/micorek">Jakub Micorek</a>, 
              <a href="https://scholar.google.es/citations?user=vnZv5acAAAAJ&hl=en">Marc Masana</a>, 
              <a href="https://scholar.google.com/citations?user=oDDqnQ4AAAAJ&hl=en">Mateusz Kozinski</a>, <br>
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>


              <br>
        <em>Intelligent Vehicle Conference</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2305.18953">arxiv</a>
        /
              code
        /
              video
              <p></p>

            </td>
          </tr> 

     
     
        
      <!-- Academic Services -->
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
            <td>
        <heading>Academic Service</heading>
          <tr>
            <td>
              
              <ul>
                  <li> <strong>Conference Reviewer</strong>: ECCV 2022, ISMAR 2023, CVPR 2023, NeurIPS 2023, WACV 2024, CVPR 2024, ECCV 2024, NeurIPS 2024, NeurIPS 2024 Dataset and Benchmark Track, ICLR 2025, CVPR 2025 <br>
		   <li> <strong>Journal Reviewer</strong>: TPAMI 2023, TNNLS 2023, IEEE Trans. Multimedia 2023, Pattern Recognition Letters 2024, Trans. Image Processing 2024 <br>
              </ul>
            </td>
          </tr>
                     </td>
          </tr>
      </table>
      
      <!-- Teaching -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
            <td>
        <heading>Teaching</heading>
          <tr>
            <td>
              
              <ul>
                  <li> <strong>Deep Learning and Neural Networks I</strong> - Exercise<br>
		   <li> <strong>Machine Learning: Supervised Techniques</strong> - Exercise<br>
		   <li> <strong>Deep Learning and Neural Networks II</strong> - Exercise<br>
		   <li> <strong>Machine Learning: Unsupervised Techniques</strong> - Exercise<br>
              </ul>
            </td>
          </tr>
                     </td>
          </tr>
      </table>
      
      <!-- Activity -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
            <td>
        <heading>Activity</heading>
          <tr>
            <td>
              
              <ul>
                  <li> <a href="https://iplab.dmi.unict.it/icvss2023/Home">International Computer Vision Summer School 2023</a><br>
              </ul>
            </td>
          </tr>
                     </td>
          </tr>
      </table>
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          template from <a href="https://jonbarron.info/"><font size="2">Jon Barrion</font></a>
          <!-- <br> -->
          <!-- Last updated: Mar 2023 -->
        </font>
        </p>
        </td>
      </tr>
      </table>
        

      </td>
    </tr>
  </table>
</body>

</html>
