<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Wei Lin</title>
  
  <meta name="author" content="Wei Lin">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Wei Lin</name>
              </p>
              <p style="color:rgb(255,0,0);">I am currently on the market for positions of Intern, PostDoc or research scientist.
              </p>
              <p>I am a PhD student at the <a href="https://www.tugraz.at/institute/icg/home">Institute of Computer Graphics and Vision</a>, <a href="https://www.tugraz.at/home">Graz University of Technology</a> (TU Graz ICG) in Austria. I am supervised by Prof. <a href="https://scholar.google.com/citations?user=_pq05Q4AAAAJ&hl=en">Horst Bischof</a> (TU Graz ICG) and Prof. <a href="https://scholar.google.ca/citations?user=pxhCcH0AAAAJ&hl=en">Hilde Kuehne</a> (Goethe University Frankfurt, <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a>)
              </p>

              <p>
              	 Previously, I received my Master's degree in Electrical and Computer Engineering at the <a href="https://www.tum.de/">Technical University of Munich</a> in Germany, and my Bachelor's degree in Eletronic and Information Engineering at the <a href="https://ev.buaa.edu.cn/">Beihang University</a> in China. 
              </p>
              <p style="text-align:center">
                <a href="mailto:wei.lin@icg.tugraz.at">Email</a> &nbsp/&nbsp
                <a href="data_lin/CV_Wei_Lin.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=JJRr8c8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/wlin-at">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/wei-lin-69a083169/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://twitter.com/WeiLinCV">Twitter</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images_lin/wei_lin.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images_lin/wei_lin.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <ul>
            <li><strong>03/2023</strong> Application to the <a href="https://cvpr2023.thecvf.com/Conferences/2023/CallForDoctoralConsortium">CVPR 2023 Doctoral Consortium</a> is accepted (acceptance rate 13%)! </li>
            <li><strong>03/2023</strong> One paper is accepted to <strong>Robotics and Automation Letters</strong>! </li>
            <li><strong>02/2023</strong> Two papers are accepted to <strong>CVPR 2023</strong>! </li>
            <li><strong>07/2022</strong> One paper is accepted to <strong>ECCV 2022</strong>! </li>
            </ul>
              <heading>Research</heading>
              <p>
                I am interested in computer vision and machine learning in general. My research is mainly about vision-language models, transfer learning, domain adaptation and video understanding.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			
			
         <tr onmouseout="maxi_stop()" onmouseover="maxi_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='maxi_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/maxi_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function maxi_start() {
                  document.getElementById('maxi_image').style.opacity = "1";
                }

                function maxi_stop() {
                  document.getElementById('maxi_image').style.opacity = "0";
                }
                maxi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>MAtch, eXpand and Improve: Unsupervised Finetuning for Zero-Shot Action Recognition with Language Knowledge
</papertitle>
              <br>
              <strong>Wei Lin</strong>,
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a>,
              <a href="https://scholar.google.com/citations?user=qZtU1L4AAAAJ&hl=en">Nina Shvetsova</a>, <br>
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://scholar.google.com/citations?user=oDDqnQ4AAAAJ&hl=en">Mateusz Kozinski</a>, 
              <a href="https://rpand002.github.io/">Rameswar Panda</a>, <br>
              <a href="https://www.rogerioferis.org/">Rogerio Feris</a>, 
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              <br>
        	In collaboration with the <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a>
              <br>
        	Arxiv 2023
              <br>
              <a href="https://arxiv.org/abs/2303.08914">arxiv</a>
        /
              <a href="https://github.com/wlin-at/MAXI">code</a>
        /
              video
              <p></p>
              <p>Unsupervised finetuning of Vision-Language models for zero-shot and few-shot action recognition.</p>
            </td>
          </tr> 		
			
     
            <tr onmouseout="vitta_stop()" onmouseover="vitta_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='vitta_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/vitta_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function vitta_start() {
                  document.getElementById('vitta_image').style.opacity = "1";
                }

                function vitta_stop() {
                  document.getElementById('vitta_image').style.opacity = "0";
                }
                vitta_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Video Test-Time Adaptation for Action Recognition</papertitle>
              <br>
              <strong>*Wei Lin</strong>,
              *<a href="https://scholar.google.com/citations?user=cES2rkAAAAAJ&hl=en">Muhammad Jehanzeb Mirza</a>,
              <a href="https://scholar.google.com/citations?user=oDDqnQ4AAAAJ&hl=en">Mateusz Kozinski</a>, <br>
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              (*equal contribution)
              <br>
        <em>CVPR</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2211.15393">arxiv</a>
        /
              <a href="https://github.com/wlin-at/ViTTA">code</a>
        /
              video
              <p></p>
              <p>Test-time adaptation of video action recognition against common distribution shifts.</p>
            </td>
          </tr> 
          
       
          <tr onmouseout="actmad_stop()" onmouseover="actmad_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='actmad_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/actmad_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function actmad_start() {
                  document.getElementById('actmad_image').style.opacity = "1";
                }

                function actmad_stop() {
                  document.getElementById('actmad_image').style.opacity = "0";
                }
                actmad_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>ActMAD: Activation Matching to Align Distributions for Test-Time-Training</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=cES2rkAAAAAJ&hl=en">Muhammad Jehanzeb Mirza</a>,
              <a href="https://www.irs.kit.edu/People_1853.php">Pol JaneÃÅ Soneira</a>,
              <strong>Wei Lin</strong>, <br>
              <a href="https://scholar.google.com/citations?user=oDDqnQ4AAAAJ&hl=en">Mateusz Kozinski</a>, 
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>


              <br>
        <em>CVPR</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2211.12870">arxiv</a>
        /
              code
        /
              video
              <p></p>

            </td>
          </tr> 
          
          

     
     
       <tr onmouseout="cycda_stop()" onmouseover="cycda_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cycda_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images_lin/cycda_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/cycda_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function cycda_start() {
                  document.getElementById('cycda_image').style.opacity = "1";
                }

                function cycda_stop() {
                  document.getElementById('cycda_image').style.opacity = "0";
                }
                cycda_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>CycDA: Unsupervised Cycle Domain Adaptation to Learn from Image to Video</papertitle>
              <br>
              <strong>Wei Lin</strong>,
              <a href="https://annusha.github.io/">Anna Kukleva</a>,
              <a href="https://www.researchgate.net/profile/Kunyang-Sun">Kunyang Sun</a>, <br>
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              <br>
        <em>ECCV</em>, 2022
              <br>
              <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136630684.pdf">paper</a>
        /
              <a href="https://arxiv.org/abs/2203.16244">arxiv</a>
        /
              <a href="https://github.com/wlin-at/CycDA">code</a>
        /
              <a href="https://www.youtube.com/watch?v=0mUuhkL_3zM">video</a>
              <p></p>
              <p>Unsupervised image-to-video domain adaptation.</p>
            </td>
          </tr> 
          
                   <tr onmouseout="mate_stop()" onmouseover="mate_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mate_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/mate_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function mate_start() {
                  document.getElementById('mate_image').style.opacity = "1";
                }

                function mate_stop() {
                  document.getElementById('mate_image').style.opacity = "0";
                }
                mate_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>MATE: Masked Autoencoders are Online 3D Test-Time Learners</papertitle>
              <br>
              *<a href="https://scholar.google.com/citations?user=cES2rkAAAAAJ&hl=en">Muhammad Jehanzeb Mirza</a>,
              *<a href="https://dlsrbgg33.github.io/">Inkyu Shin</a>,
              *<strong>Wei Lin</strong>, 
              <br>
              Andreas Schriebl,
              <a href="https://www.researchgate.net/profile/Kunyang-Sun">Kunyang Sun</a>,
              <a href="https://sites.google.com/view/jaesungchoe">Jaesung Choe</a>,
              <br>
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://scholar.google.com/citations?user=oDDqnQ4AAAAJ&hl=en">Mateusz Kozinski</a>, 
              <a href="https://scholar.google.com/citations?user=XA8EOlEAAAAJ&hl=en">In So Kweon</a>,
              <br>
              <a href="https://sites.google.com/site/kjyoon/">Kun-Jin Yoon</a>, 
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              (*equal contribution)
              <br>
        	Arxiv 2022
              <br>
              <a href="https://arxiv.org/abs/2211.11432">arxiv</a>
        /
              code
        /
              video
              <p></p>

            </td>
          </tr> 
          
         <tr onmouseout="cycdaex_stop()" onmouseover="cycdaex_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cycdaex_image'><video  width=100% height=100% muted autoplay loop>
                <source src="dummy" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/cycda_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function cycdaex_start() {
                  document.getElementById('cycdaex_image').style.opacity = "1";
                }

                function cycdaex_stop() {
                  document.getElementById('cycdaex_image').style.opacity = "0";
                }
                cycdaex_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Extended Abstract CycDA: Unsupervised Cycle Domain Adaptation to Learn from Image to Video</papertitle>
              <br>
              <strong>Wei Lin</strong>,
              <a href="https://annusha.github.io/">Anna Kukleva</a>,
              <a href="https://www.researchgate.net/profile/Kunyang-Sun">Kunyang Sun</a>, <br>
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, 
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              <br>
        <em>ECCV Workshop of Out Of Distribution Generalization in Computer Vision</em>, 2022
              <br>
              <a href="http://www.ood-cv.org/camera-ready/2/CycDA_Out_of_distribution_generalization_workshop_lin.pdf">paper</a>
        /
              <a href="https://github.com/wlin-at/CycDA">code</a>
        /
              <a href="https://www.youtube.com/watch?v=0mUuhkL_3zM">video</a>
              <p></p>
            </td>
          </tr> 
          
         <tr onmouseout="airda_stop()" onmouseover="airda_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='airda_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images_lin/airda_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/airda_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function airda_start() {
                  document.getElementById('airda_image').style.opacity = "1";
                }

                function airda_stop() {
                  document.getElementById('airda_image').style.opacity = "0";
                }
                airda_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>AIR-DA: Adversarial Image Reconstruction for Unsupervised Domain Adaptive Object Detection</papertitle>
              <br>
              <a href="https://www.researchgate.net/profile/Kunyang-Sun">Kunyang Sun</a>,
              <strong>Wei Lin</strong>,
              Haoqin Shi, <br>
              <a href="https://scholar.google.com/citations?user=GePqbSgAAAAJ&hl=en">Zhengming Zhang</a>, 
              <a href="https://scholar.google.com/citations?user=qd9zdUMAAAAJ&hl=zh-CN">Yongming Huang</a>,
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              <br>
        	IEEE Robotics and Automation Letters (RA-L) 2023
              <br>
              <a href="https://arxiv.org/abs/2303.15377">arxiv</a>
        /
              code
        /
              video
              <p></p>
            </td>
          </tr> 
          
          
         <tr onmouseout="taec_stop()" onmouseover="taec_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='taec_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images_lin/taec_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_lin/taec_screenshot.png' width="160">
              </div>
              <script type="text/javascript">
                function taec_start() {
                  document.getElementById('taec_image').style.opacity = "1";
                }

                function taec_stop() {
                  document.getElementById('taec_image').style.opacity = "0";
                }
                taec_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>TAEC: Unsupervised Action Segmentation with Temporal-Aware Embedding and Clustering</papertitle>
              <br>
              <strong>Wei Lin</strong>,
              <a href="https://annusha.github.io/">Anna Kukleva</a>,
              <a href="https://snototter.github.io/research/">Horst Possegger</a>, <br>
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>,
              <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
              <br>
        <em>Computer Vision Winter Workshop</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2303.05166">arxiv</a>
        /
              code
        /
              video
              <p></p>
            </td>
          </tr> 
          
          

     
     
        
      <!-- Academic Services -->
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
            <td>
        <heading>Academic Service</heading>
          <tr>
            <td>
              
              <ul>
                  <li> <strong>Conference Reviewer</strong>: ECCV 2022, CVPR 2023, NeurIPS 2023 <br>

              </ul>
            </td>
          </tr>
                     </td>
          </tr>
      </table>
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          template from <a href="https://jonbarron.info/"><font size="2">Jon Barrion</font></a>
          <!-- <br> -->
          <!-- Last updated: Mar 2023 -->
        </font>
        </p>
        </td>
      </tr>
      </table>
        

      </td>
    </tr>
  </table>
</body>

</html>
