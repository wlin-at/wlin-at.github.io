<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Comparison Visual Instruction Tuning">
  <meta name="keywords" content="MAXI">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CaD-VI</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!--<link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://wlin-at.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://wlin-at.github.io/maxi">
            MAXI
          </a>
          <a class="navbar-item" href="https://wlin-at.github.io/vitta">
            ViTTA
          </a>
          <a class="navbar-item" href="https://jmiemirza.github.io/ActMAD/">
            ActMAD
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Comparison Visual Instruction Tuning</h1>
          <div class="is-size-4 publication-authors">
          
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://wlin-at.github.io/">Wei Lin</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://jmiemirza.github.io/">Muhammad Jehanzeb Mirza</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.co.il/citations?user=ER4dt8cAAAAJ&hl=iw">Sivan Doveh</a><sup>3,4</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.rogerioferis.org/">Rogerio Feris</a><sup>7</sup>,
            </span>
            <span class="author-block">
              <a href="https://english.tau.ac.il/profile/raja">Raja Giryes</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.at/citations?user=tvUH3WMAAAAJ&hl=en">Sepp Hochreiter</a><sup>1,6</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a><sup>7</sup>
            </span>          
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ELLIS Unit, LIT AI Lab, Institute for Machine Learning, JKU Linz, Austria</span>
            <span class="author-block"><sup>2</sup>TU Graz ICG, Austria</span>
            <span class="author-block"><sup>3</sup>IBM Research, Israel</span>
            <span class="author-block"><sup>4</sup>Weizmann Institute of Science, Israel</span>
            <span class="author-block"><sup>5</sup>Tel-Aviv University, Israel</span>
            <span class="author-block"><sup>6</sup>NXAI GmbH, Austria</span>
            <span class="author-block"><sup>7</sup>MIT-IBM Watson AI Lab, USA</span>
          </div>
	
	<a href="https://huggingface.co/datasets/wlin21at/CaD-Inst">&#129303 Dataset Repo</a>
	
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!--span class="link-block">
                <a href="https://arxiv.org/pdf/2303.08914.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span-->
              <span class="link-block">
                <a href="dummy"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              

              
             <!-- Dataset Link. -->
              
              <span class="link-block">
                <a href="https://huggingface.co/datasets/wlin21at/CaD-Inst"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/wlin-at/CaD-VI"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
             <!-- Video Link. -->
              <span class="link-block">
                <a href="dummy"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>







<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Comparing two images in terms of Commonalities and Differences (CaD) is a fundamental human capability that forms the basis of advanced visual reasoning and interpretation.
          </p>
          <p>
            We develop and contribute a new two-phase approach CaD-VI for collecting synthetic visual instructions, together with an instruction-following dataset CaD-Inst containing 349K image pairs with CaD instructions collected using CaD-VI.
          </p>
          <p>
            Additionally, we propose an evaluation benchmark with 7.5K open-ended QAs to assess the CaD understanding abilities of LMMs.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    
    
<section class="section">
  <div class="container is-max-desktop">
    <!-- Attention Heatmaps -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <hr>
        <h2 class="title is-3">Pipeline</h2>
          
         <img src="media/cad_vi/pipeline.png" class="center"/>
        <div class="content has-text-justified">
          <br>  
          
            Two-phase data collection: In Phase-1, we leverage captions for image pairs and the Mixtral 8x7B model to generate CaD VI data - CaD-Inst V1 (278K), and perform visual instruction tuning on it to arrive at the Phase-1 model CaD-LLaVA-V1.
           </p> 
           <p>
In Phase-2, we leverage CaD-LLaVAV 1 to generate CaD VI data on additional image pairs and collect CaD-Inst-V2 (71K). Visual instruction tuning with
CaD-InstV 1 and CaD-InstV 2 leads to our final model CaD-LLaVA-V2 
          </p>
        
          </div>
          
        <img src="media/cad_vi/two_phase_data_collect_example.png" class="center"/>
        <div class="content has-text-justified">
          <br>  
          <p>
            Anther example of (a) Phase-1 LLM-collected CaD summary and (b) Phase-2 LMM-collected CaD summary
          </p>
        
        </div>
        
        <br>  
        
     
     </div>
      
    </div>
    
    

       
    
     <!-- Data Statistics -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <hr>
        <h2 class="title is-3">Data Statistics</h2>
          
         <img src="media/cad_vi/word_cloud_in_cad_summary.png" class="center"/>
        <div class="content has-text-justified">
          <br>  
          
            Word clouds of CaD summaries in (a) Phase-1 data and (b) Phase-2 data collections
           </p> 

        
          </div>
          
        <img src="media/cad_vi/distribution_questions_answers_cad_qa.png" class="center"/>
        <div class="content has-text-justified">
          <br>  
          <p>
            Distribution of (a) questions (first 5 words) and (b) answers (first 3 words) in our collected evaluation benchmark CaD-QA
          </p>
        
        </div>
        
        <br>  
        
     
     </div>
      
    </div>
    
    

    
       
    
    <!-- Examples of Text Bag -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <hr>
        <h2 class="title is-3">Examples of Collected QA Pairs</h2>
          
        <img src="media/cad_vi/qa_pair_visualization_part1.png" class="center"/>
        <img src="media/cad_vi/qa_pair_visualization_part2.png" class="center"/>
        <div class="content has-text-justified">
          <br>  
          <p>
            Examples of Q&A pairs in our CaD-QA benchmark together with LMM predicted answers and the corresponding LLM evaluation ratings for the prediction (Red and green texts denote incorrect and correct description).
          </p>
        </div>
          
      </div>
    </div>
    <hr>
    
    
     <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <hr>
        <h2 class="title is-3">Reasoning on Binary Image Selection Task</h2>
          
        <img src="media/cad_vi/bison_visualization.png" class="center"/>
        <div class="content has-text-justified">
          <br>  
          <p>
            Examples of predictions on binary image selection task (selection of the matched image given a text query). Here we instruct the LMMs to, besides the selection, also give a reasoning for the selection (Red and green texts denote incorrect and correct predictions). 
          </p>
        </div>
          
      </div>
    </div>
    <hr>
    

 

</div>
</section>    
 



    
    
    <!-- Paper video. -->
    <!--
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
    <!--/ Paper video. -->
    
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{lin2024comparison,
  title={Comparison Visual Instruction Tuning},
  author={Lin, Wei and Mirza, Muhammad Jehanzeb and Doveh, Sivan and Feris, Rogerio and Giryes, Raja and Hochreiter, Sepp and Karlinsky, Leonid},
  journal={arXiv preprint},
  year={2024}
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/wlin-at" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. The template is from <a rel="license"
                                                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
